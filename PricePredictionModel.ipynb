{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "889652ee",
   "metadata": {},
   "source": [
    "### Import Modules/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87fda1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66440d2",
   "metadata": {},
   "source": [
    "### Import Data (Train and Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83289418",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape:  (1450, 81)\n",
      "Test Data Shape:  (1440, 80)\n"
     ]
    }
   ],
   "source": [
    "df_house_train = pd.read_csv(\n",
    "    r\"train.csv\",\n",
    "    low_memory=False,\n",
    ")\n",
    "df_house_test = pd.read_csv(\n",
    "    r\"test.csv\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# drop columns with all NaN values\n",
    "df_house_train.dropna(axis=1, how=\"all\")\n",
    "df_house_test.dropna(axis=1, how=\"all\")\n",
    "\n",
    "# limit to only residential properties\n",
    "residential = [\"FV\", \"RH\", \"RL\", \"RP\", \"RM\"]\n",
    "df_house_train = df_house_train[df_house_train[\"MSZoning\"].isin(residential)]\n",
    "df_house_test = df_house_test[df_house_test[\"MSZoning\"].isin(residential)]\n",
    "print(\"Train Data Shape: \", df_house_train.shape)\n",
    "print(\"Test Data Shape: \", df_house_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e20e883",
   "metadata": {},
   "source": [
    "### Combine Train and Test Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d46690db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Train and Test data sets\n",
    "    # this allows for all added column/features to be available in both \n",
    "Combined_df = pd.concat([df_house_train, df_house_test], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "575cfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing data with zero\n",
    "\n",
    "def fill_missing_data(df: pd.DataFrame):\n",
    "    for col_ in df.columns:\n",
    "        if df[col_].dtype == \"object\":\n",
    "            # fill 'NONE' for categorical features\n",
    "            df[col_].fillna(\"NONE\", inplace=True)\n",
    "        else:\n",
    "            # fill zero for numerical features\n",
    "            df[col_].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "fill_missing_data(Combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0741c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_house_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11892\\2179281871.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorrelation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_house_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtop_10_corr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"SalePrice\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SalePrice\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_house_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_10_corr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m correlation_hm = sns.heatmap(\n\u001b[0;32m      5\u001b[0m     \u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_house_train' is not defined"
     ]
    }
   ],
   "source": [
    "correlation = df_house_train.corr()\n",
    "top_10_corr = correlation.nlargest(11, \"SalePrice\")[\"SalePrice\"].index\n",
    "cm = np.corrcoef(df_house_train[top_10_corr].values.T)\n",
    "correlation_hm = sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    annot_kws={\"size\": 10},\n",
    "    yticklabels=top_10_corr.values,\n",
    "    xticklabels=top_10_corr.values,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef14a68",
   "metadata": {},
   "source": [
    "#### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a65ebec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_df = Combined_df[Combined_df.GrLivArea < 4400]\n",
    "Combined_df = Combined_df[Combined_df.TotalBsmtSF < 2500]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7f0b485",
   "metadata": {},
   "source": [
    "#### Building the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4918a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f1b0fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to use in model \n",
    "Features = top_10_corr.copy().delete([0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f860d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of data set\n",
    "train_df = Combined_df.copy()\n",
    "# Filter to rows included in df_house_train set for train \n",
    "train_df = train_df[train_df.Id.isin(df_house_train.Id)]\n",
    "\n",
    "# Set up Train and Validation Sets\n",
    "    # test size = 20%\n",
    "    # random state = 42\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    train_df[Features], train_df[\"SalePrice\"], test_size=0.2, random_state=42\n",
    ")\n",
    "_, X_valid_with_id, _, _ = train_test_split(\n",
    "    train_df.drop(\"SalePrice\", axis=1),\n",
    "    train_df[\"SalePrice\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "# Create copy of comb_df\n",
    "    # limit to only rows included in df_house_test for test \n",
    "test_df = Combined_df.copy()\n",
    "test_df = test_df[test_df.Id.isin(df_house_test.Id)]\n",
    "\n",
    "X_test = test_df[Features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "48594a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed to accommodate UI. When not using, this will increase performance\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_valid = scaler.transform(X_valid)\n",
    "# X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cb898",
   "metadata": {},
   "source": [
    "#### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7a25ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d6762d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGmodel = XGBRegressor(n_estimators=3000, learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "17bd65af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.005, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=3000, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "75c3d753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9873510440836475\n",
      "Validation Accuracy : 0.8746850219615414\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy : {XGmodel.score(X_train,y_train)}\")\n",
    "print(f\"Validation Accuracy : {XGmodel.score(X_valid,y_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1bf8b2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1461</td>\n",
       "      <td>130621.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1462</td>\n",
       "      <td>144504.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1463</td>\n",
       "      <td>179915.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1464</td>\n",
       "      <td>187423.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1465</td>\n",
       "      <td>204784.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>2915</td>\n",
       "      <td>75791.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>2916</td>\n",
       "      <td>88354.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>2917</td>\n",
       "      <td>155029.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>2918</td>\n",
       "      <td>106297.054688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>2919</td>\n",
       "      <td>246167.046875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1434 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "1450  1461  130621.921875\n",
       "1451  1462  144504.875000\n",
       "1452  1463  179915.859375\n",
       "1453  1464  187423.484375\n",
       "1454  1465  204784.312500\n",
       "...    ...            ...\n",
       "2885  2915   75791.718750\n",
       "2886  2916   88354.835938\n",
       "2887  2917  155029.281250\n",
       "2888  2918  106297.054688\n",
       "2889  2919  246167.046875\n",
       "\n",
       "[1434 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGdata = test_df\n",
    "XGdata[\"SalePrice\"] = XGmodel.predict(X_test)\n",
    "XGdata = XGdata[[\"Id\", \"SalePrice\"]]\n",
    "XGdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "42f5ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for UI\n",
    "import pickle\n",
    "# Save the XGmodel to a file\n",
    "with open('xgboost_model.pkl', 'wb') as file:\n",
    "    pickle.dump(XGmodel, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d337b98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "43f221103f953d3e0d93840edd77be981e5a5e0e42edc048e3de5278c46a3390"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
